from typing import List, Dict, Any, Optional
from datetime import datetime

from watchmen_ai.dspy.module.ask_for_report import AskForReportModule
from watchmen_ai.hypothesis.rag.rag_emb_service import (
    search_semantic_content, 
    search_similar_content,
    get_rag_embedding_service
)
from watchmen_ai.hypothesis.service.analysis_service import load_simulate_result_by_simulation_id
from watchmen_utilities import ExtendedBaseModel




class ReportAnalyzer(ExtendedBaseModel):
    """Historical report analyzer for deep conversation"""

    def __init__(self):
        super().__init__()

    async def retrieve_historical_reports(self, user_query: str, 
                                         semantic_sections: Optional[List[str]] = None,
                                         limit: int = 5) -> List[Dict[str, Any]]:
        """æ£€ç´¢ç›¸å…³å†å²åˆ†ææŠ¥å‘Šï¼Œæ”¯æŒè¯­ä¹‰æ®µè½è¿‡æ»¤å’Œæ™ºèƒ½å›é€€æœºåˆ¶
        
        Args:
            user_query: ç”¨æˆ·æŸ¥è¯¢
            semantic_sections: è¯­ä¹‰æ®µè½ç±»å‹è¿‡æ»¤ï¼Œé»˜è®¤ä¸º ["executive_summary", "conclusion", "recommendation"]
            limit: è¿”å›ç»“æœæ•°é‡é™åˆ¶
        """
        if semantic_sections is None:
            semantic_sections = ["executive_summary", "conclusion", "recommendation"]
            
        try:
            # ä½¿ç”¨è¯­ä¹‰æœç´¢è·å–ç›¸å…³æŠ¥å‘Š
            search_results = await search_semantic_content(
                user_query,
                semantic_sections=semantic_sections,
                limit=limit * 2  # è·å–æ›´å¤šç»“æœä»¥æ‰¾åˆ°å”¯ä¸€æŠ¥å‘Š
            )
        except Exception as e:
            # å¦‚æœè¯­ä¹‰æœç´¢å¤±è´¥ï¼Œå›é€€åˆ°åŸºç¡€æœç´¢
            print(f"è¯­ä¹‰æœç´¢å¤±è´¥ï¼Œå›é€€åˆ°åŸºç¡€æœç´¢: {e}")
            search_results = await search_similar_content(user_query, limit * 2)

        # æŒ‰ simulation_id åˆ†ç»„è·å–å”¯ä¸€æŠ¥å‘Š
        unique_reports = self._group_results_by_simulation(search_results)

        # è·å–å®Œæ•´æŠ¥å‘Šå†…å®¹
        historical_reports = []
        processed_count = 0

        for simulation_id, best_result in unique_reports.items():
            if processed_count >= limit:
                break

            try:
                # è·å–å®Œæ•´æŠ¥å‘Šå†…å®¹
                full_content = await self._get_full_report_content(simulation_id)
                
                if full_content:
                    report_data = self._create_report_data(best_result, simulation_id, full_content)
                    historical_reports.append(report_data)
                    processed_count += 1
                else:
                    print(f"æ— æ³•è·å–ä»¿çœŸ {simulation_id} çš„å®Œæ•´å†…å®¹")

            except Exception as e:
                print(f"æ£€ç´¢ä»¿çœŸ {simulation_id} å®Œæ•´å†…å®¹æ—¶å‡ºé”™: {e}")
                # å¯é€‰ï¼šä½¿ç”¨éƒ¨åˆ†å†…å®¹ä½œä¸ºå›é€€
                fallback_data = self._create_fallback_report_data(best_result, simulation_id)
                if fallback_data:
                    historical_reports.append(fallback_data)
                    processed_count += 1

        return historical_reports
    
    def _group_results_by_simulation(self, search_results) -> Dict[str, Any]:
        """æŒ‰ simulation_id åˆ†ç»„æœç´¢ç»“æœï¼Œä¿ç•™æœ€é«˜ç›¸å…³åº¦çš„ç»“æœ"""
        unique_reports = {}
        for result in search_results:
            simulation_id = result.document.simulation_id
            if simulation_id not in unique_reports:
                unique_reports[simulation_id] = result
            else:
                # ä¿ç•™ç›¸å…³åº¦æ›´é«˜çš„ç»“æœ
                if result.score > unique_reports[simulation_id].score:
                    unique_reports[simulation_id] = result
        return unique_reports
    
    async def _get_full_report_content(self, simulation_id: str) -> Optional[str]:
        """è·å–å®Œæ•´æŠ¥å‘Šå†…å®¹"""
        try:
            simulate_res = load_simulate_result_by_simulation_id(simulation_id)
            return simulate_res["simulation_result"]["result"]["challengeMarkdown"]
        except Exception as e:
            print(f"è·å–ä»¿çœŸ {simulation_id} å†…å®¹å¤±è´¥: {e}")
            return None
    
    def _create_report_data(self, best_result, simulation_id: str, full_content: str) -> Dict[str, Any]:
        """åˆ›å»ºæŠ¥å‘Šæ•°æ®å­—å…¸"""
        return {
            "id": best_result.document.id,
            "simulation_id": simulation_id,
            "title": best_result.document.challenge_title,
            "content": full_content,
            "content_type": "full_report",
            "semantic_section": best_result.document.semantic_section,
            "section_title": getattr(best_result.document, 'section_title', ''),
            "relevance_score": best_result.score,  # ä½¿ç”¨æ­£ç¡®çš„åˆ†æ•°
            "distance": best_result.distance,
            "token_count": getattr(best_result.document, 'token_count', 0),
            "chunk_index": getattr(best_result.document, 'chunk_index', 0),
            "total_chunks": getattr(best_result.document, 'total_chunks', 1),
            "created_at": best_result.document.created_at,
            "metadata": getattr(best_result.document, 'metadata', {})
        }
    
    def _create_fallback_report_data(self, best_result, simulation_id: str) -> Optional[Dict[str, Any]]:
        """åˆ›å»ºå›é€€æŠ¥å‘Šæ•°æ®ï¼ˆä½¿ç”¨éƒ¨åˆ†å†…å®¹ï¼‰"""
        try:
            return {
                "id": best_result.document.id,
                "simulation_id": simulation_id,
                "title": best_result.document.challenge_title,
                "content": best_result.document.markdown_content,  # ä½¿ç”¨éƒ¨åˆ†å†…å®¹
                "content_type": "partial_report",
                "semantic_section": best_result.document.semantic_section,
                "section_title": getattr(best_result.document, 'section_title', ''),
                "relevance_score": best_result.score,
                "distance": best_result.distance,
                "token_count": getattr(best_result.document, 'token_count', 0),
                "chunk_index": getattr(best_result.document, 'chunk_index', 0),
                "total_chunks": getattr(best_result.document, 'total_chunks', 1),
                "created_at": best_result.document.created_at,
                "metadata": getattr(best_result.document, 'metadata', {}),
                "is_fallback": True
            }
        except Exception:
            return None

    async def ask_question_for_report(self, user_input:str , report_content:List[str],metrics_list:List[str]=[]) -> str:
        """Ask a question about the report content and metrics"""
        ask_for_report = AskForReportModule()
        result = ask_for_report( metrics_list,report_content,user_input)
        return result.response

    async def analyze_report_content(self, reports: List[Dict[str, Any]], user_question: str) -> Dict[str, Any]:
        """Deep analysis of full report content based on user question"""

        analysis_context = {
            "key_findings": [],
            "relevant_insights": [],
            "data_points": [],
            "recommendations": [],
            "gaps_identified": [],
            "full_reports": []  # Store full report content for comprehensive analysis
        }

        for report in reports:
            content = report.get("content", "")
            content_type = report.get("content_type", "")

            # Store full report for comprehensive access
            analysis_context["full_reports"].append({
                "source_report": report["title"],
                "full_content": content,
                "simulation_id": report["simulation_id"],
                "relevance": report["relevance_score"],
                "created_at": report["created_at"]
            })

            # Extract different types of insights from full content
            if content_type == "full_report":
                # Parse full report content to extract structured insights
                extracted_insights = self._extract_insights_from_full_report(content, report["title"],
                                                                             report["relevance_score"])

                # Merge extracted insights into analysis context
                analysis_context["key_findings"].extend(extracted_insights.get("findings", []))
                analysis_context["recommendations"].extend(extracted_insights.get("recommendations", []))
                analysis_context["relevant_insights"].extend(extracted_insights.get("insights", []))
                analysis_context["data_points"].extend(extracted_insights.get("data_points", []))
            else:
                # Handle semantic section content (fallback case)
                semantic_section = report.get("semantic_section", "")
                if semantic_section == "conclusion":
                    analysis_context["key_findings"].append({
                        "source_report": report["title"],
                        "finding": content,
                        "relevance": report["relevance_score"]
                    })
                elif semantic_section == "recommendation":
                    analysis_context["recommendations"].append({
                        "source_report": report["title"],
                        "recommendation": content,
                        "relevance": report["relevance_score"]
                    })
                elif semantic_section == "analysis":
                    analysis_context["relevant_insights"].append({
                        "source_report": report["title"],
                        "insight": content,
                        "relevance": report["relevance_score"]
                    })

        return analysis_context

    def _extract_insights_from_full_report(self, content: str, report_title: str, relevance_score: float) -> Dict[
        str, List[Dict[str, Any]]]:
        """Extract structured insights from full report content"""
        insights = {
            "findings": [],
            "recommendations": [],
            "insights": [],
            "data_points": []
        }

        # Split content into sections for analysis
        lines = content.split('\n')
        current_section = ""
        current_content = []

        for line in lines:
            line = line.strip()
            if not line:
                continue

            # Detect section headers
            if line.startswith('#'):
                # Process previous section
                if current_section and current_content:
                    section_text = ' '.join(current_content)
                    self._categorize_section_content(current_section, section_text, report_title, relevance_score,
                                                     insights)

                # Start new section
                current_section = line.lower()
                current_content = []
            else:
                current_content.append(line)

        # Process last section
        if current_section and current_content:
            section_text = ' '.join(current_content)
            self._categorize_section_content(current_section, section_text, report_title, relevance_score, insights)

        return insights

    def _categorize_section_content(self, section_header: str, content: str, report_title: str, relevance_score: float,
                                    insights: Dict[str, List[Dict[str, Any]]]):
        """Categorize section content into appropriate insight types"""
        if not content.strip():
            return

        # Categorize based on section header keywords
        if any(keyword in section_header for keyword in ['conclusion', 'summary', 'finding', 'result']):
            insights["findings"].append({
                "source_report": report_title,
                "finding": content,
                "relevance": relevance_score,
                "section": section_header
            })
        elif any(keyword in section_header for keyword in ['recommendation', 'suggestion', 'action', 'next step']):
            insights["recommendations"].append({
                "source_report": report_title,
                "recommendation": content,
                "relevance": relevance_score,
                "section": section_header
            })
        elif any(keyword in section_header for keyword in ['analysis', 'insight', 'observation', 'trend']):
            insights["insights"].append({
                "source_report": report_title,
                "insight": content,
                "relevance": relevance_score,
                "section": section_header
            })
        elif any(keyword in section_header for keyword in ['data', 'metric', 'number', 'statistic', 'kpi']):
            insights["data_points"].append({
                "source_report": report_title,
                "data_point": content,
                "relevance": relevance_score,
                "section": section_header
            })
        else:
            # Default to insights for unclassified content
            insights["insights"].append({
                "source_report": report_title,
                "insight": content,
                "relevance": relevance_score,
                "section": section_header
            })

    async def generate_enhanced_analysis_report(self, reports: List[Dict[str, Any]], 
                                              user_query: str, 
                                              metrics_data: Dict[str, Any] = None) -> str:
        """ç”Ÿæˆå¢å¼ºçš„åˆ†ææŠ¥å‘Šï¼ŒåŸºäºå®Œæ•´å†å²æŠ¥å‘Šå†…å®¹
        
        Args:
            reports: å†å²æŠ¥å‘Šåˆ—è¡¨
            user_query: ç”¨æˆ·æŸ¥è¯¢
            metrics_data: æŒ‡æ ‡æ•°æ®
        """
        report_sections = []
        
        # æ·»åŠ æŠ¥å‘Šå¤´éƒ¨
        report_sections.append("# ğŸ“Š æ™ºèƒ½å†å²åˆ†ææŠ¥å‘Š")
        report_sections.append(f"**æŸ¥è¯¢å†…å®¹**: {user_query}")
        report_sections.append(f"**ç”Ÿæˆæ—¶é—´**: {self._get_current_time()}")
        report_sections.append(f"**æ•°æ®æ¥æº**: {len(reports)} ä¸ªç›¸å…³å†å²æŠ¥å‘Š")
        
        if reports:
            # æŒ‰è¯­ä¹‰æ®µè½ç±»å‹ç»„ç»‡å‘ç°
            semantic_findings = self._organize_reports_by_semantic_type(reports)
            
            # æ‰§è¡Œæ‘˜è¦
            if 'executive_summary' in semantic_findings:
                report_sections.append("\n## ğŸ¯ æ‰§è¡Œæ‘˜è¦")
                for report in semantic_findings['executive_summary'][:2]:
                    report_sections.append(f"### {report['title']}")
                    report_sections.append(f"**ç›¸å…³åº¦**: {report['relevance_score']:.3f}")
                    report_sections.append(f"**æ‘˜è¦**: {self._extract_summary(report['content'])}")
                    report_sections.append("")
            
            # å…³é”®ç»“è®º
            if 'conclusion' in semantic_findings:
                report_sections.append("\n## ğŸ“‹ å…³é”®ç»“è®º")
                for report in semantic_findings['conclusion'][:3]:
                    report_sections.append(f"### {report['title']}")
                    report_sections.append(f"**ç›¸å…³åº¦**: {report['relevance_score']:.3f}")
                    conclusions = self._extract_conclusions(report['content'])
                    for conclusion in conclusions[:2]:
                        report_sections.append(f"- {conclusion}")
                    report_sections.append("")
            
            # æ¨èè¡ŒåŠ¨
            if 'recommendation' in semantic_findings:
                report_sections.append("\n## ğŸ’¡ æ¨èè¡ŒåŠ¨")
                for report in semantic_findings['recommendation'][:3]:
                    report_sections.append(f"### {report['title']}")
                    priority = self._calculate_priority(report['relevance_score'])
                    report_sections.append(f"**ä¼˜å…ˆçº§**: {priority}")
                    recommendations = self._extract_recommendations(report['content'])
                    for rec in recommendations[:2]:
                        report_sections.append(f"- {rec}")
                    report_sections.append("")
            
            # å…¶ä»–ç›¸å…³åˆ†æ
            other_sections = {k: v for k, v in semantic_findings.items() 
                            if k not in ['executive_summary', 'conclusion', 'recommendation']}
            if other_sections:
                report_sections.append("\n## ğŸ“ˆ è¡¥å……åˆ†æ")
                for section_type, reports_list in other_sections.items():
                    section_name = self._get_section_display_name(section_type)
                    report_sections.append(f"### {section_name}")
                    for report in reports_list[:2]:
                        summary = self._extract_summary(report['content'])
                        report_sections.append(f"- **{report['title']}**: {summary}")
                    report_sections.append("")
        
        # æ•°æ®æ´å¯Ÿ
        # if metrics_data:
        #     report_sections.append("\n## ğŸ“Š å½“å‰æ•°æ®æ´å¯Ÿ")
        #     for key, value in metrics_data.items():
        #         if isinstance(value, dict) and 'trend' in value:
        #             trend_indicator = "ğŸ“ˆ" if value.get('trend', 0) > 0 else "ğŸ“‰" if value.get('trend', 0) < 0 else "â¡ï¸"
        #             report_sections.append(f"- **{key}**: {value.get('current', 'N/A')} {trend_indicator}")
        #         else:
        #             report_sections.append(f"- **{key}**: {value}")
        
        # æ™ºèƒ½å»ºè®®
        report_sections.append("\n## ğŸš€ æ™ºèƒ½å»ºè®®")
        suggestions = self._generate_intelligent_suggestions(reports, metrics_data)
        for suggestion in suggestions:
            report_sections.append(f"- {suggestion}")
        
        # ç›¸å…³æŠ¥å‘Šç´¢å¼•
        if reports:
            report_sections.append("\n## ğŸ“š ç›¸å…³æŠ¥å‘Šç´¢å¼•")
            for i, report in enumerate(reports[:5], 1):
                fallback_indicator = " (éƒ¨åˆ†å†…å®¹)" if report.get('is_fallback') else ""
                report_sections.append(
                    f"{i}. **{report['title']}**{fallback_indicator} "
                    f"(ç›¸å…³åº¦: {report['relevance_score']:.3f}, "
                    f"ç±»å‹: {report['content_type']}, "
                    f"è¯­ä¹‰æ®µè½: {report.get('semantic_section', 'general')})"
                )
        
        return "\n".join(report_sections)
    
    def _organize_reports_by_semantic_type(self, reports: List[Dict[str, Any]]) -> Dict[str, List[Dict[str, Any]]]:
        """æŒ‰è¯­ä¹‰æ®µè½ç±»å‹ç»„ç»‡æŠ¥å‘Š"""
        organized = {}
        for report in reports:
            semantic_section = report.get('semantic_section', 'general')
            if semantic_section not in organized:
                organized[semantic_section] = []
            organized[semantic_section].append(report)
        
        # æŒ‰ç›¸å…³åº¦æ’åºæ¯ä¸ªç±»å‹çš„ç»“æœ
        for section_type in organized:
            organized[section_type].sort(key=lambda x: x.get('relevance_score', 0), reverse=True)
        
        return organized
    
    def _extract_summary(self, content: str, max_length: int = 200) -> str:
        """ä»å†…å®¹ä¸­æå–æ‘˜è¦"""
        if not content:
            return "æ— å¯ç”¨æ‘˜è¦"
        
        # ç®€å•çš„æ‘˜è¦æå–ï¼šå–å‰å‡ å¥è¯
        sentences = content.split('ã€‚')
        summary = ""
        for sentence in sentences:
            if len(summary + sentence) <= max_length:
                summary += sentence + "ã€‚"
            else:
                break
        
        return summary.strip() or content[:max_length] + "..."
    
    def _extract_conclusions(self, content: str) -> List[str]:
        """ä»å†…å®¹ä¸­æå–ç»“è®º"""
        conclusions = []
        lines = content.split('\n')
        
        for line in lines:
            line = line.strip()
            if any(keyword in line.lower() for keyword in ['ç»“è®º', 'conclusion', 'æ€»ç»“', 'å‘ç°']):
                if len(line) > 10:  # è¿‡æ»¤å¤ªçŸ­çš„è¡Œ
                    conclusions.append(line)
        
        return conclusions[:5]  # æœ€å¤šè¿”å›5ä¸ªç»“è®º
    
    def _extract_recommendations(self, content: str) -> List[str]:
        """ä»å†…å®¹ä¸­æå–æ¨è"""
        recommendations = []
        lines = content.split('\n')
        
        for line in lines:
            line = line.strip()
            if any(keyword in line.lower() for keyword in ['å»ºè®®', 'recommendation', 'æ¨è', 'åº”è¯¥']):
                if len(line) > 10:  # è¿‡æ»¤å¤ªçŸ­çš„è¡Œ
                    recommendations.append(line)
        
        return recommendations[:5]  # æœ€å¤šè¿”å›5ä¸ªæ¨è
    
    def _calculate_priority(self, score: float) -> str:
        """æ ¹æ®ç›¸å…³åº¦åˆ†æ•°è®¡ç®—ä¼˜å…ˆçº§"""
        if score >= 0.8:
            return "ğŸ”´ é«˜ä¼˜å…ˆçº§"
        elif score >= 0.6:
            return "ğŸŸ¡ ä¸­ä¼˜å…ˆçº§"
        else:
            return "ğŸŸ¢ ä½ä¼˜å…ˆçº§"
    
    def _get_section_display_name(self, section_type: str) -> str:
        """è·å–è¯­ä¹‰æ®µè½ç±»å‹çš„æ˜¾ç¤ºåç§°"""
        display_names = {
            'hypothesis': 'å‡è®¾åˆ†æ',
            'conclusion': 'ç»“è®ºæ€»ç»“', 
            'recommendation': 'æ¨èè¡ŒåŠ¨',
            'analysis': 'æ·±åº¦åˆ†æ',
            'executive_summary': 'æ‰§è¡Œæ‘˜è¦',
            'future_action': 'æœªæ¥è¡ŒåŠ¨',
            'general': 'ä¸€èˆ¬å†…å®¹'
        }
        return display_names.get(section_type, section_type.title())
    
    def _generate_intelligent_suggestions(self, reports: List[Dict[str, Any]], 
                                        metrics_data: Dict[str, Any] = None) -> List[str]:
        """åŸºäºæŠ¥å‘Šå’ŒæŒ‡æ ‡æ•°æ®ç”Ÿæˆæ™ºèƒ½å»ºè®®"""
        suggestions = []
        
        # åŸºäºæŠ¥å‘Šæ•°é‡çš„å»ºè®®
        if len(reports) == 0:
            suggestions.append("å»ºè®®æ‰©å±•æœç´¢èŒƒå›´æˆ–è°ƒæ•´æŸ¥è¯¢å…³é”®è¯ä»¥è·å–æ›´å¤šç›¸å…³å†å²æ¡ˆä¾‹")
        elif len(reports) < 3:
            suggestions.append("ç›¸å…³å†å²æ¡ˆä¾‹è¾ƒå°‘ï¼Œå»ºè®®ç»“åˆå®æ—¶æ•°æ®è¿›è¡Œæ·±å…¥åˆ†æ")
        
        # åŸºäºè¯­ä¹‰æ®µè½åˆ†å¸ƒçš„å»ºè®®
        semantic_types = set(report.get('semantic_section', 'general') for report in reports)
        if 'recommendation' not in semantic_types:
            suggestions.append("ç¼ºå°‘å…·ä½“çš„è¡ŒåŠ¨å»ºè®®ï¼Œå»ºè®®æŸ¥æ‰¾æ›´å¤šåŒ…å«æ¨èæªæ–½çš„å†å²æ¡ˆä¾‹")
        if 'conclusion' not in semantic_types:
            suggestions.append("å»ºè®®è¡¥å……ç»“è®ºåˆ†æä»¥æ›´å¥½åœ°ç†è§£é—®é¢˜çš„è§£å†³æ–¹æ¡ˆ")
        
        # åŸºäºå›é€€æ•°æ®çš„å»ºè®®
        fallback_count = sum(1 for report in reports if report.get('is_fallback'))
        if fallback_count > 0:
            suggestions.append(f"æœ‰ {fallback_count} ä¸ªæŠ¥å‘Šä½¿ç”¨äº†éƒ¨åˆ†å†…å®¹ï¼Œå»ºè®®æ£€æŸ¥æ•°æ®å®Œæ•´æ€§")
        
        # åŸºäºæŒ‡æ ‡æ•°æ®çš„å»ºè®®
        # if metrics_data:
        #     trending_down = any(
        #         isinstance(v, dict) and v.get('trend', 0) < 0
        #         for v in metrics_data.values()
        #     )
        #     if trending_down:
        #         suggestions.append("æ£€æµ‹åˆ°ä¸‹é™è¶‹åŠ¿ï¼Œå»ºè®®ä¼˜å…ˆå…³æ³¨é£é™©æ§åˆ¶å’Œæ”¹è¿›æªæ–½")
        
        # åŸºäºæŠ¥å‘Šè´¨é‡çš„å»ºè®®
        # high_quality_reports = [r for r in reports if r.get('relevance_score', 0) > 0.7]
        # if len(high_quality_reports) < len(reports) * 0.5:
        #     suggestions.append("éƒ¨åˆ†åŒ¹é…æŠ¥å‘Šç›¸å…³åº¦è¾ƒä½ï¼Œå»ºè®®ç»†åŒ–æŸ¥è¯¢æ¡ä»¶æˆ–æ‰©å±•æœç´¢èŒƒå›´")
        #
        # # é»˜è®¤å»ºè®®
        # if not suggestions:
        #     suggestions.extend([
        #         "å»ºè®®ç»“åˆå¤šä¸ªç»´åº¦çš„å†å²æ•°æ®è¿›è¡Œç»¼åˆåˆ†æ",
        #         "å…³æ³¨è¶‹åŠ¿å˜åŒ–å’Œå¼‚å¸¸æŒ‡æ ‡ï¼ŒåŠæ—¶è°ƒæ•´ç­–ç•¥",
        #         "å®šæœŸå›é¡¾å’Œæ›´æ–°åˆ†ææ¨¡å‹ä»¥æé«˜å‡†ç¡®æ€§"
        #     ])
        
        return suggestions[:5]  # é™åˆ¶å»ºè®®æ•°é‡
    
    def _get_current_time(self) -> str:
        """è·å–å½“å‰æ—¶é—´çš„æ ¼å¼åŒ–å­—ç¬¦ä¸²"""
        return datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    async def generate_conversation_response(self, analysis_context: Dict[str, Any],
                                             user_question: str, metrics_data: Dict[str, Any] = None) -> str:
        """ç”Ÿæˆå¯¹è¯å¼å“åº”ï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰"""
        # ä¸ºäº†å‘åå…¼å®¹ï¼Œä¿ç•™åŸæœ‰æ–¹æ³•ä½†ä½¿ç”¨æ–°çš„å¢å¼ºåŠŸèƒ½
        reports = analysis_context.get("full_reports", [])
        
        # è½¬æ¢æ ¼å¼ä»¥é€‚é…æ–°æ–¹æ³•
        formatted_reports = []
        for report in reports:
            formatted_report = {
                "title": report.get("source_report", "æœªçŸ¥æŠ¥å‘Š"),
                "content": report.get("full_content", ""),
                "relevance_score": report.get("relevance", 0.0),
                "simulation_id": report.get("simulation_id", ""),
                "content_type": "full_report",
                "semantic_section": "general",
                "created_at": report.get("created_at", "")
            }
            formatted_reports.append(formatted_report)
        
        return await self.generate_enhanced_analysis_report(formatted_reports, user_question, metrics_data)
